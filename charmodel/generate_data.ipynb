{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rural-village",
   "metadata": {},
   "source": [
    "# Generate name dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "challenging-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp mllib.charrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-comfort",
   "metadata": {},
   "source": [
    "Here we will create the dataset which can help us to import names from the text file for name generation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "federal-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import re\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitting-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Reserved tokens for things like padding and EOS symbols.\n",
    "PAD = \"<pad>\"\n",
    "EOS = \"<EOS>\"\n",
    "BOS = \"<BOS>\"\n",
    "RESERVED_TOKENS = [PAD, EOS, BOS]\n",
    "NUM_RESERVED_TOKENS = len(RESERVED_TOKENS)\n",
    "PAD_ID = RESERVED_TOKENS.index(PAD)  # Normally 0\n",
    "EOS_ID = RESERVED_TOKENS.index(EOS)  # Normally 1\n",
    "BOS_ID = RESERVED_TOKENS.index(BOS)  # Normally 2\n",
    "\n",
    "\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, charset, file_lists=List[str], length=10 ):\n",
    "        self.samples = []\n",
    "        self.charset = charset + '\\0'\n",
    "        self.length = length\n",
    "        self.char_codec = LabelEncoder()\n",
    "        \n",
    "        for file in file_lists:\n",
    "            self.read_file(file)\n",
    "            \n",
    "        self._init_dataset()\n",
    "    \n",
    "    def _init_dataset(self):\n",
    "        self.char_codec.fit(list(self.charset))\n",
    "    \n",
    "    def to_one_hot(self, codec, values):\n",
    "        value_idxs = codec.transform(values)\n",
    "        return torch.eye(len(codec.classes_))[value_idxs]\n",
    "    \n",
    "    def one_hot_sample(self, *args):\n",
    "        # get arguments to convert to one_hot\n",
    "        t_name = self.to_one_hot(self.char_codec, list(args[0]))\n",
    "        return t_name\n",
    "        \n",
    "    def read_file(self, file_path:str):\n",
    "        print(file_path)\n",
    "        with open(file_path,'r') as name_file:\n",
    "            for name in name_file.read().splitlines()[1:]:\n",
    "                filtered_name = re.sub(r'\\W+', '', name)\n",
    "                if len(filtered_name) < self.length:\n",
    "                    filtered_name += '\\0' * (self.length - len(filtered_name))\n",
    "                else:\n",
    "                    filtered_name = filtered_name[:self.length-1] + '\\0'\n",
    "                self.samples.append(filtered_name.upper())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx:int)-> str:\n",
    "        name = self.samples[idx]\n",
    "        print(name)\n",
    "        return self.one_hot_sample(name)\n",
    "    \n",
    "def pad_collate(batch):\n",
    "    \"\"\" Pads input and target to the same length \"\"\"\n",
    "    \n",
    "    names = batch\n",
    "    names_pad = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=PAD_ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pleasant-charleston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/first_names.all.txt\n"
     ]
    }
   ],
   "source": [
    "#dataset = TESNamesDataset(data_root, charset, length)\n",
    "charset = set([ c.upper() for c in string.ascii_letters ])\n",
    "charset = ''.join(sorted(charset))\n",
    "ds = NamesDataset(file_lists=['./data/first_names.all.txt'], charset = charset + \"-' \")\n",
    "trainset, valset = random_split(ds, [131566, 32892])\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=10, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(valset, batch_size=10, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "systematic-cable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAVITA\u0000\u0000\u0000\u0000\n",
      "BRINGHURS\u0000\n",
      "KUNTAKINT\u0000\n",
      "TERRALL\u0000\u0000\u0000\n",
      "RIGNALL\u0000\u0000\u0000\n",
      "DONALYNN\u0000\u0000\n",
      "SHAWANDRA\u0000\n",
      "SUKINA\u0000\u0000\u0000\u0000\n",
      "ALLEENA\u0000\u0000\u0000\n",
      "SAWAIRA\u0000\u0000\u0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 30])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-porter",
   "metadata": {},
   "source": [
    "# Convert it into Fastai Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-patent",
   "metadata": {},
   "source": [
    "In general, when we have pytorch dataset like above, we can easily convert it into FastAI dataset by using `Transform` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "catholic-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "smart-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lists=['./data/first_names.all.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "residential-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = []\n",
    "with open(file_lists[0],'r') as file:\n",
    "    for name in file.read().splitlines()[1:]:\n",
    "        filtered_name = re.sub(r'\\W+', '', name)\n",
    "        names_list.append(filtered_name.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "related-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tfms = [lambda x: ['xxbos'] + list(x), Numericalize()]\n",
    "len_tfms = [lambda x: torch.tensor(len(x)+1, dtype=torch.int32)]\n",
    "#tgt_tfms = [lambda x: list(x)[1:]]\n",
    "\n",
    "dsrc = Datasets(names_list, tfms=[src_tfms, len_tfms], splits=RandomSplitter(valid_pct=0.2)(names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surrounded-sailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131567, 32891)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsrc.train), len(dsrc.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "focal-outreach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#6) ['xxbos','A','A','B','A','N'], tensor(6, dtype=torch.int32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.decode(dsrc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ItemTransform\n",
    "def after_item(obj):\n",
    "    return (obj[0][:-1], obj[0][1:], obj[1])\n",
    "\n",
    "def pad_input_chunk_new(samples, n_inp=2,**kwargs):\n",
    "    \"Pad `samples` by adding padding by chunks of size `seq_len`\"\n",
    "    \n",
    "    max_len = max([len(s[n]) for s in samples for n in range(n_inp)])\n",
    "    padeds = [[pad_chunk(s[n],pad_len=max_len,**kwargs) for n in range(n_inp) ] for s in samples]\n",
    "    \n",
    "    return [(*p, *s[n_inp:]) for p, s in zip(padeds, samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "annoying-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dsrc.dataloaders(after_item=after_item, before_batch=pad_input_chunk_new, bs=4, n_inp=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "personal-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "concerned-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_b = (b[0],b[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-tennis",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Let's record all hyperparamters found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "studied-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(dsrc.vocab)\n",
    "PAD_ID = 1\n",
    "BOS_ID = 2\n",
    "embed_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-internship",
   "metadata": {},
   "source": [
    "# Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "foreign-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils import rnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from dotmap import DotMap\n",
    "from typing import Dict\n",
    "\n",
    "import collections\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spanish-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(pl.LightningModule):\n",
    "    def __init__(self, hidden_size, embed_size, embed):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.embeds = embed\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, inp, lengths):\n",
    "\n",
    "        emb = self.embeds(inp)\n",
    "        output, hidden = self.rnn(emb)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "engaged-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(pl.LightningModule):\n",
    "    def __init__(self, embed, embed_size, hidden_size, output_size, max_len):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.embeds = embed\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first = True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward_step(self, input, hidden, encoder_output):\n",
    "        del encoder_output # todo : use it for attention\n",
    "        \n",
    "        emb = self.embeds(input)\n",
    "        o , h = self.rnn(emb, hidden)\n",
    "        \n",
    "        out = self.out(o)\n",
    "        return F.log_softmax(out, -1), h\n",
    "    \n",
    "    def forward(self, enc_h, enc_out, tgt = None):\n",
    "        \"\"\" Uses teacher enforcing, relies on tgt starting with BOS\"\"\"\n",
    "        decoder_input = tgt\n",
    "        # uses decoder input as teacher enforcing\n",
    "        \n",
    "        if tgt is None:        # inference\n",
    "            # during test time, we generate all the decoder values\n",
    "            batch_size = enc_h.size(0) if enc_h is not None else 1\n",
    "            decoder_input = torch.LongTensor(\n",
    "                [batch_size* [BOS_ID]]).view(batch_size, 1).to(enc_h.device)\n",
    "        \n",
    "        decoder_hidden = enc_h\n",
    "            \n",
    "        decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden, enc_out)\n",
    "            \n",
    "        return decoder_output, decoder_hidden\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "temporal-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_cm(preds, labels, nb_clss):\n",
    "    \"\"\"Calculates all confusion matrix based metrics.\"\"\"\n",
    "    acc = (labels == preds).float().mean()\n",
    "\n",
    "    cm = torch.zeros((nb_clss, nb_clss), device=labels.device)\n",
    "    for label, pred in zip(labels, preds):\n",
    "        cm[label.long(), pred.long()] += 1\n",
    "\n",
    "    tp = cm.diagonal()[1:].sum()\n",
    "    fp = cm[:, 1:].sum() - tp\n",
    "    fn = cm[1:, :].sum() - tp\n",
    "    return (acc, tp, fp, fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "experimental-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLightningModule(pl.LightningModule):\n",
    "    def __init__(self, hp:Dict ):\n",
    "        super().__init__()\n",
    "        self.hparams= hp\n",
    "        \n",
    "        # share embedding layer by encoder or decoder\n",
    "        self.embed = nn.Embedding(hp.vocab_size, hp.embedding_size, padding_idx = PAD_ID)\n",
    "        \n",
    "        self.encoder = EncoderRNN(hp.hidden_size, hp.embedding_size, self.embed)\n",
    "        self.decoder = DecoderRNN(self.embed, hp.embedding_size, hp.hidden_size, hp.vocab_size, hp.max_len)\n",
    "        \n",
    "        self.criterion = nn.NLLLoss(ignore_index = PAD_ID)\n",
    "        \n",
    "        \n",
    "    def forward(self, src, lengths, tgt=None):\n",
    "        encoder_output, encoder_hidden = self.encoder(src, lengths)\n",
    "        outputs,hidden = self.decoder(encoder_hidden, encoder_output, tgt)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, tgt, lengths = batch\n",
    "\n",
    "        \n",
    "        output = self.forward(src, lengths, tgt)\n",
    "        loss = self.criterion(output.view(-1,output.shape[2]), tgt.view(-1))\n",
    "        #loss = self.criterion(output.data, tgt.data)    # both are packed\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, tgt, lengths = batch\n",
    "\n",
    "        \n",
    "        output = self.forward(src, lengths, tgt)\n",
    "        loss = self.criterion(output.view(-1,output.shape[2]), tgt.view(-1))\n",
    "        \n",
    "         # metrics\n",
    "        preds = torch.argmax(output.data, dim=-1)\n",
    "        # preds = elementwise_apply(torch.argmax, output, -1)\n",
    "        (acc, tp, fp, fn) = acc_cm(preds, tgt.data, vocab_size)\n",
    "        \n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc,\n",
    "            'tp': tp,\n",
    "            'fp': fp,\n",
    "            'fn': fn\n",
    "        }\n",
    "        preds_pad, _ = rnn.pad_packed_sequence(\n",
    "            rnn.PackedSequence(preds, output.batch_sizes),\n",
    "            batch_first=True,\n",
    "            padding_value=text_encoder.PAD_ID)\n",
    "        tgts_pad, _ = rnn.pad_packed_sequence(tgt,\n",
    "                                              batch_first=True,\n",
    "                                              padding_value=text_encoder.PAD_ID)\n",
    "\n",
    "        bleu = metrics.compute_bleu(tgts_pad.tolist(), preds_pad.tolist())\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc,\n",
    "            'tp': tp,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'bleu': bleu\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "abandoned-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_ID = 1\n",
    "\n",
    "class RNN(pl.LightningModule):\n",
    "    def __init__(self, hp:Dict):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hparams = hp\n",
    "        \n",
    "        self.num_layers = hp.num_layers\n",
    "        self.hidden_size = hp.embedding_size\n",
    "        self.output_size = hp.vocab_size\n",
    "        self.input_size = hp.vocab_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.output_size)\n",
    "        self.rnn = nn.LSTM(input_size = self.input_size, hidden_size=self.hidden_size, num_layers = self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "        self.criterion = nn.NLLLoss(ignore_index = PAD_ID)\n",
    "\n",
    "        \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "\n",
    "        \n",
    "        embedding  = self.embedding(input_seq)\n",
    "        output, hidden_state = self.rnn(embedding.unsqueeze(0), hidden_state)\n",
    "        output = self.decoder(output)\n",
    "    \n",
    "        return F.log_softmax(output, -1), (hidden_state[0].detach(), hidden_state[1].detach())\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        return h,c\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, tgt, lengths = batch\n",
    "\n",
    "        hidden_state = self.init_hidden(src.shape[0])\n",
    "        loss = 0\n",
    "        chunk_len = src.shape[1]\n",
    "        \n",
    "        for j in range(chunk_len):\n",
    "            output, hidden_state = self.forward(src[:,j],hidden_state)\n",
    "            output = output.reshape(output.shape[1]*output.shape[0],-1)\n",
    "            \n",
    "            loss += self.criterion(output, tgt[:,j])\n",
    "        \n",
    "        loss = loss / chunk_len\n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, tgt, lengths = batch\n",
    "\n",
    "        hidden_state = self.init_hidden(src.shape[0])\n",
    "        loss = 0\n",
    "        chunk_len = src.shape[1]\n",
    "        \n",
    "        for j in range(chunk_len):\n",
    "            output, hidden_state = self.forward(src[:,j],hidden_state)\n",
    "            output = output.reshape(output.shape[1]*output.shape[0],-1)\n",
    "            \n",
    "            loss += self.criterion(output, tgt[:,j])\n",
    "        \n",
    "        loss = loss / chunk_len\n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def generate(self, initial_char = 'A', predict_len = 15, temperature=0.85):\n",
    "        hidden, cell = self.init_hidden(batch_size = 1)\n",
    "        initial_input = self.char2tensor(initial_char)\n",
    "        predicted_str = initial_char\n",
    "        \n",
    "        for p in range(len(inital_char)-1):\n",
    "            _, (hidden, cell) = self.rnn(initial_input[p].view(1).to(device), hidden, cell)\n",
    "            \n",
    "        last_char = initial_input[-1]\n",
    "        \n",
    "        for p in range(predict_len):\n",
    "            output, (hidden , cell) = self.rnn(last_char.view(1).to(device), hidden, cell)\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_char = torch.multinomial(output_dist, 1)[0]\n",
    "            \n",
    "            # convert back to string\n",
    "            predicted_char = all_chars[top_char]\n",
    "            predicted += predicted_char\n",
    "            last_char  = top_char\n",
    "            \n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-guidance",
   "metadata": {},
   "source": [
    "# Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "sudden-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "unique-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "generic-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = DotMap({'vocab_size': vocab_size, \n",
    "          'embedding_size': embed_size,\n",
    "          'hidden_size': embed_size,\n",
    "            'max_len': 15,\n",
    "            'num_layers':1,\n",
    "            'lr': 0.02})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bibliographic-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Seq2SeqLightningModule(hparams)\n",
    "model = RNN(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "hazardous-replica",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(fast_dev_run=False, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "sporting-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 10.8 K\n",
      "1 | rnn       | LSTM      | 16.3 K\n",
      "2 | decoder   | Linear    | 3.2 K \n",
      "3 | criterion | NLLLoss   | 0     \n",
      "----------------------------------------\n",
      "30.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "30.4 K    Total params\n",
      "0.121     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7962d92840648b7aa100e169a83fa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 34, in fetch\n    data = next(self.dataset_iter)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 120, in create_batches\n    yield from map(self.do_batch, self.chunkify(res))\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 146, in do_batch\n    def do_batch(self, b): return self.retain(self.create_batch(self.before_batch(b)), b)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 145, in create_batch\n    def create_batch(self, b): return (fa_collate,fa_convert)[self.prebatched](b)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 50, in fa_collate\n    else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 50, in <listcomp>\n    else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 49, in fa_collate\n    return (default_collate(t) if isinstance(b, _collate_types)\n  File \"/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 53, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/torch/storage.py\", line 135, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Shared memory manager connection has timed out at ../torch/lib/libshm/core.cpp:99\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-7603b4db56c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/accelerators/legacy/cpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/accelerators/legacy/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mshould_check_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/profiler/profilers.py\u001b[0m in \u001b[0;36mprofile_iterable\u001b[0;34m(self, iterable, action_name)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\u001b[0m in \u001b[0;36m_with_is_last\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;31m# yield last and has next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mrequest_next_batch\u001b[0;34m(loader_iters)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Breaking condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Recursively apply to collection items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/fastai/fastai/data/load.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# called in context of main process (not workers/subprocesses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;31m# fix issue 2899. If the process start method isn't fork, the data will be copied to cuda in learner one_batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_start_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fork\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/torch/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 34, in fetch\n    data = next(self.dataset_iter)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 120, in create_batches\n    yield from map(self.do_batch, self.chunkify(res))\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 146, in do_batch\n    def do_batch(self, b): return self.retain(self.create_batch(self.before_batch(b)), b)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 145, in create_batch\n    def create_batch(self, b): return (fa_collate,fa_convert)[self.prebatched](b)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 50, in fa_collate\n    else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 50, in <listcomp>\n    else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n  File \"/Users/puneet/Projects/fastai/fastai/data/load.py\", line 49, in fa_collate\n    return (default_collate(t) if isinstance(b, _collate_types)\n  File \"/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 53, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/torch/storage.py\", line 135, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Shared memory manager connection has timed out at ../torch/lib/libshm/core.cpp:99\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dls.train, dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "coupled-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7318), started 0:00:03 ago. (Use '!kill 7318' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4150a0a6fc4501d5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4150a0a6fc4501d5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-tobago",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
