{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accepting-uncertainty",
   "metadata": {},
   "source": [
    "# Generate name dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "muslim-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp mllib.charrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-steps",
   "metadata": {},
   "source": [
    "Here we will create the dataset which can help us to import names from the text file for name generation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "superior-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import re\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outer-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Reserved tokens for things like padding and EOS symbols.\n",
    "PAD = \"<pad>\"\n",
    "EOS = \"<EOS>\"\n",
    "BOS = \"<BOS>\"\n",
    "RESERVED_TOKENS = [PAD, EOS, BOS]\n",
    "NUM_RESERVED_TOKENS = len(RESERVED_TOKENS)\n",
    "PAD_ID = RESERVED_TOKENS.index(PAD)  # Normally 0\n",
    "EOS_ID = RESERVED_TOKENS.index(EOS)  # Normally 1\n",
    "BOS_ID = RESERVED_TOKENS.index(BOS)  # Normally 2\n",
    "\n",
    "\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, charset, file_lists=List[str], length=10 ):\n",
    "        self.samples = []\n",
    "        self.charset = charset + '\\0'\n",
    "        self.length = length\n",
    "        self.char_codec = LabelEncoder()\n",
    "        \n",
    "        for file in file_lists:\n",
    "            self.read_file(file)\n",
    "            \n",
    "        self._init_dataset()\n",
    "    \n",
    "    def _init_dataset(self):\n",
    "        self.char_codec.fit(list(self.charset))\n",
    "    \n",
    "    def to_one_hot(self, codec, values):\n",
    "        value_idxs = codec.transform(values)\n",
    "        return torch.eye(len(codec.classes_))[value_idxs]\n",
    "    \n",
    "    def one_hot_sample(self, *args):\n",
    "        # get arguments to convert to one_hot\n",
    "        t_name = self.to_one_hot(self.char_codec, list(args[0]))\n",
    "        return t_name\n",
    "        \n",
    "    def read_file(self, file_path:str):\n",
    "        print(file_path)\n",
    "        with open(file_path,'r') as name_file:\n",
    "            for name in name_file.read().splitlines()[1:]:\n",
    "                filtered_name = re.sub(r'\\W+', '', name)\n",
    "                if len(filtered_name) < self.length:\n",
    "                    filtered_name += '\\0' * (self.length - len(filtered_name))\n",
    "                else:\n",
    "                    filtered_name = filtered_name[:self.length-1] + '\\0'\n",
    "                self.samples.append(filtered_name.upper())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx:int)-> str:\n",
    "        name = self.samples[idx]\n",
    "        print(name)\n",
    "        return self.one_hot_sample(name)\n",
    "    \n",
    "def pad_collate(batch):\n",
    "    \"\"\" Pads input and target to the same length \"\"\"\n",
    "    \n",
    "    names = batch\n",
    "    names_pad = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=PAD_ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distributed-outline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/first_names.all.txt\n"
     ]
    }
   ],
   "source": [
    "#dataset = TESNamesDataset(data_root, charset, length)\n",
    "charset = set([ c.upper() for c in string.ascii_letters ])\n",
    "charset = ''.join(sorted(charset))\n",
    "ds = NamesDataset(file_lists=['./data/first_names.all.txt'], charset = charset + \"-' \")\n",
    "trainset, valset = random_split(ds, [131566, 32892])\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=10, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(valset, batch_size=10, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "numerical-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAVITA\u0000\u0000\u0000\u0000\n",
      "BRINGHURS\u0000\n",
      "KUNTAKINT\u0000\n",
      "TERRALL\u0000\u0000\u0000\n",
      "RIGNALL\u0000\u0000\u0000\n",
      "DONALYNN\u0000\u0000\n",
      "SHAWANDRA\u0000\n",
      "SUKINA\u0000\u0000\u0000\u0000\n",
      "ALLEENA\u0000\u0000\u0000\n",
      "SAWAIRA\u0000\u0000\u0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 30])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-conflict",
   "metadata": {},
   "source": [
    "# Convert it into Fastai Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-solution",
   "metadata": {},
   "source": [
    "In general, when we have pytorch dataset like above, we can easily convert it into FastAI dataset by using `Transform` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cheap-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "royal-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lists=['./data/first_names.all.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wanted-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = []\n",
    "with open(file_lists[0],'r') as file:\n",
    "    for name in file.read().splitlines()[1:]:\n",
    "        filtered_name = re.sub(r'\\W+', '', name)\n",
    "        names_list.append(filtered_name.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cognitive-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tfms = [lambda x: ['xxbos'] + list(x), Numericalize()]\n",
    "len_tfms = [lambda x: torch.tensor(len(x)+1, dtype=torch.int32)]\n",
    "#tgt_tfms = [lambda x: list(x)[1:]]\n",
    "\n",
    "dsrc = Datasets(names_list, tfms=[src_tfms, len_tfms], splits=RandomSplitter(valid_pct=0.2)(names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rural-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131567, 32891)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsrc.train), len(dsrc.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "public-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#6) ['xxbos','A','A','B','A','N'], tensor(6, dtype=torch.int32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.decode(dsrc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "chemical-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ItemTransform\n",
    "def after_item(obj):\n",
    "    return (obj[0][:-1], obj[0][1:], obj[1])\n",
    "\n",
    "def pad_input_chunk_new(samples, n_inp=2,**kwargs):\n",
    "    \"Pad `samples` by adding padding by chunks of size `seq_len`\"\n",
    "    \n",
    "    max_len = max([len(s[n]) for s in samples for n in range(n_inp)])\n",
    "    padeds = [[pad_chunk(s[n],pad_len=max_len,**kwargs) for n in range(n_inp) ] for s in samples]\n",
    "    \n",
    "    return [(*p, *s[n_inp:]) for p, s in zip(padeds, samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "molecular-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dsrc.dataloaders(after_item=after_item, before_batch=pad_input_chunk_new, bs=4, n_inp=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "based-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "indoor-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_b = (b[0],b[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-sterling",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Let's record all hyperparamters found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accurate-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(dsrc.vocab)\n",
    "PAD_ID = 1\n",
    "BOS_ID = 2\n",
    "embed_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-greene",
   "metadata": {},
   "source": [
    "# Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "concerned-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils import rnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from dotmap import DotMap\n",
    "from typing import Dict\n",
    "\n",
    "import collections\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "numerous-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(pl.LightningModule):\n",
    "    def __init__(self, hidden_size, embed_size, embed):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.embeds = embed\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, inp, lengths):\n",
    "\n",
    "        emb = self.embeds(inp)\n",
    "        output, hidden = self.rnn(emb)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "assumed-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(pl.LightningModule):\n",
    "    def __init__(self, embed, embed_size, hidden_size, output_size, max_len):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.embeds = embed\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first = True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward_step(self, input, hidden, encoder_output):\n",
    "        del encoder_output # todo : use it for attention\n",
    "        \n",
    "        emb = self.embeds(input)\n",
    "        o , h = self.rnn(emb, hidden)\n",
    "        \n",
    "        out = self.out(o)\n",
    "        return F.log_softmax(out, -1), h\n",
    "    \n",
    "    def forward(self, enc_h, enc_out, tgt = None):\n",
    "        \"\"\" Uses teacher enforcing, relies on tgt starting with BOS\"\"\"\n",
    "        decoder_input = tgt\n",
    "        # uses decoder input as teacher enforcing\n",
    "        \n",
    "        if tgt is None:        # inference\n",
    "            # during test time, we generate all the decoder values\n",
    "            batch_size = enc_h.size(0) if enc_h is not None else 1\n",
    "            decoder_input = torch.LongTensor(\n",
    "                [batch_size* [BOS_ID]]).view(batch_size, 1).to(enc_h.device)\n",
    "        \n",
    "        decoder_hidden = enc_h\n",
    "            \n",
    "        decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden, enc_out)\n",
    "            \n",
    "        return decoder_output, decoder_hidden\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "activated-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_cm(preds, labels, nb_clss):\n",
    "    \"\"\"Calculates all confusion matrix based metrics.\"\"\"\n",
    "    acc = (labels == preds).float().mean()\n",
    "\n",
    "    cm = torch.zeros((nb_clss, nb_clss), device=labels.device)\n",
    "    for label, pred in zip(labels, preds):\n",
    "        cm[label.long(), pred.long()] += 1\n",
    "\n",
    "    tp = cm.diagonal()[1:].sum()\n",
    "    fp = cm[:, 1:].sum() - tp\n",
    "    fn = cm[1:, :].sum() - tp\n",
    "    return (acc, tp, fp, fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "usual-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLightningModule(pl.LightningModule):\n",
    "    def __init__(self, hp:Dict, learning_rate ):\n",
    "        super().__init__()\n",
    "        self.hparams= hp\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # share embedding layer by encoder or decoder\n",
    "        self.embed = nn.Embedding(hp.vocab_size, hp.embedding_size, padding_idx = PAD_ID)\n",
    "        \n",
    "        self.encoder = EncoderRNN(hp.hidden_size, hp.embedding_size, self.embed)\n",
    "        self.decoder = DecoderRNN(self.embed, hp.embedding_size, hp.hidden_size, hp.vocab_size, hp.max_len)\n",
    "        \n",
    "        self.criterion = nn.NLLLoss(ignore_index = PAD_ID)\n",
    "        \n",
    "        \n",
    "    def forward(self, src, lengths, tgt=None):\n",
    "        encoder_output, encoder_hidden = self.encoder(src, lengths)\n",
    "        outputs,hidden = self.decoder(encoder_hidden, encoder_output, tgt)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, tgt, lengths = batch\n",
    "\n",
    "        \n",
    "        output = self.forward(src, lengths, tgt)\n",
    "        loss = self.criterion(output.view(-1,output.shape[2]), tgt.view(-1))\n",
    "        #loss = self.criterion(output.data, tgt.data)    # both are packed\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, tgt, lengths = batch\n",
    "\n",
    "        \n",
    "        output = self.forward(src, lengths, tgt)\n",
    "        loss = self.criterion(output.view(-1,output.shape[2]), tgt.view(-1))\n",
    "        \n",
    "         # metrics\n",
    "        preds = torch.argmax(output.data, dim=-1)\n",
    "        # preds = elementwise_apply(torch.argmax, output, -1)\n",
    "        (acc, tp, fp, fn) = acc_cm(preds, tgt.data, vocab_size)\n",
    "        \n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc,\n",
    "            'tp': tp,\n",
    "            'fp': fp,\n",
    "            'fn': fn\n",
    "        }\n",
    "        preds_pad, _ = rnn.pad_packed_sequence(\n",
    "            rnn.PackedSequence(preds, output.batch_sizes),\n",
    "            batch_first=True,\n",
    "            padding_value=text_encoder.PAD_ID)\n",
    "        tgts_pad, _ = rnn.pad_packed_sequence(tgt,\n",
    "                                              batch_first=True,\n",
    "                                              padding_value=text_encoder.PAD_ID)\n",
    "\n",
    "        bleu = metrics.compute_bleu(tgts_pad.tolist(), preds_pad.tolist())\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc,\n",
    "            'tp': tp,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'bleu': bleu\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=(self.lr or self.learning_rate))\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "intensive-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_ID = 1\n",
    "\n",
    "class RNN(pl.LightningModule):\n",
    "    def __init__(self, hp:Dict, learning_rate=0.02):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hparams = hp\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_layers = hp.num_layers\n",
    "        self.hidden_size = hp.hidden_size\n",
    "        self.output_size = hp.vocab_size\n",
    "        self.input_size = hp.vocab_size\n",
    "        self.embed_size = hp.embedding_size\n",
    "        self.char2tensor = dls.numericalize.o2i\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.embed_size)\n",
    "        self.rnn = nn.LSTM(input_size = self.embed_size, hidden_size=self.hidden_size, num_layers = self.num_layers, batch_first=True)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "        \n",
    "        #self.criterion = nn.NLLLoss()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "\n",
    "        \n",
    "        embedding  = self.embedding(input_seq)\n",
    "        output, hidden_state = self.rnn(embedding, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        #output = F.log_softmax(output, -1)\n",
    "        return output, hidden_state\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        return h,c\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, tgt, lengths = batch\n",
    "\n",
    "        hidden_state = self.init_hidden(src.shape[0])\n",
    "        loss = 0\n",
    "        chunk_len = src.shape[1]\n",
    "        \n",
    "        #for j in range(chunk_len):\n",
    "        #    output, hidden_state = self.forward(src[:,j],hidden_state)\n",
    "        #    output = output.reshape(output.shape[1]*output.shape[0],-1)\n",
    "        output, hidden_state = self.forward(src, hidden_state)\n",
    "        output = output.reshape(output.shape[1]*output.shape[0],-1)\n",
    "        loss = self.criterion(output, tgt.flatten())\n",
    "        \n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, tgt, lengths = batch\n",
    "\n",
    "        hidden_state = self.init_hidden(src.shape[0])\n",
    "        loss = 0\n",
    "        chunk_len = src.shape[1]\n",
    "        \n",
    "        #for j in range(chunk_len):\n",
    "        #    output, hidden_state = self.forward(src[:,j],hidden_state)\n",
    "        #    output = output.reshape(output.shape[1]*output.shape[0],-1)\n",
    "        output, hidden_state = self.forward(src, hidden_state)\n",
    "        output = output.reshape(output.shape[1]*output.shape[0],-1)\n",
    "        loss = self.criterion(output, tgt.flatten())\n",
    "        \n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # generate some names\n",
    "        names = ['A','B','R','KAR','TE','CHRI']\n",
    "        output = {n: self.generate(initial_char=n) for n in names}\n",
    "        print(output)\n",
    "        \n",
    "\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        #optimizer = torch.optim.SGD(self.parameters(), lr=self.hparams.lr)\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "        #optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=self.hparams.lr*2, steps_per_epoch=10, epochs=4)\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def generate(self, initial_char = 'A', predict_len = 15, temperature=0.85):\n",
    "        hidden, cell = self.init_hidden(batch_size = 1)\n",
    "        \n",
    "        initial_input = TensorText([self.char2tensor[c] for c in initial_char ]).cuda()\n",
    "        predicted_str = initial_char\n",
    "        \n",
    "        for p in range(len(initial_char)-1):\n",
    "            _, (hidden, cell) = self.forward(initial_input[p].view(1,1).to(device), (hidden, cell))\n",
    "        \n",
    "        last_char = initial_input[-1]\n",
    "        \n",
    "        for p in range(predict_len):\n",
    "            output, (hidden , cell) = self.forward(last_char.view(1,1).to(device), (hidden, cell))\n",
    "            # convert output to softmax\n",
    "            output = F.log_softmax(output, -1) # convert to softmax\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_char = torch.multinomial(output_dist, 1)[0]\n",
    "            \n",
    "            if top_char == PAD_ID:\n",
    "                # PADDING encountred stop\n",
    "                break\n",
    "            \n",
    "            # convert back to string\n",
    "            predicted_char = dls.numericalize.vocab[top_char]\n",
    "            #predicted_char = all_chars[top_char]\n",
    "            predicted_str += predicted_char\n",
    "            last_char  = top_char\n",
    "            \n",
    "        return predicted_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-wilson",
   "metadata": {},
   "source": [
    "# Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "blank-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "dietary-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cleared-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_ID=1\n",
    "BOS_ID=1\n",
    "\n",
    "hparams = DotMap({'vocab_size': len(dsrc.vocab), \n",
    "          'embedding_size': 30,\n",
    "          'hidden_size': 10,\n",
    "            'max_len': 15,\n",
    "            'num_layers':2,\n",
    "            'lr': 0.02})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "theoretical-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Seq2SeqLightningModule(hparams)\n",
    "model = RNN(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "seeing-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(fast_dev_run=False, logger=logger, auto_lr_find='learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | embedding | Embedding        | 10.8 K\n",
      "1 | rnn       | LSTM             | 23.8 K\n",
      "2 | decoder   | Linear           | 3.2 K \n",
      "3 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "37.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.8 K    Total params\n",
      "0.151     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "trainer.tune(model, dls.train, dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "substantial-technology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 10.8 K\n",
      "1 | rnn       | LSTM      | 16.3 K\n",
      "2 | decoder   | Linear    | 3.2 K \n",
      "3 | criterion | NLLLoss   | 0     \n",
      "----------------------------------------\n",
      "30.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "30.4 K    Total params\n",
      "0.121     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5815ee7351a4439da645634e85be281e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dls.train, dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "modern-document",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7318), started 0:00:03 ago. (Use '!kill 7318' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4150a0a6fc4501d5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4150a0a6fc4501d5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-destruction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
