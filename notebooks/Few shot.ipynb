{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "passive-breast",
   "metadata": {},
   "source": [
    "# Few shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-glance",
   "metadata": {},
   "source": [
    "Here, in this notebook, we will look into few shot / zero shot learning to fit a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-trace",
   "metadata": {},
   "source": [
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693837"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-interaction",
   "metadata": {},
   "source": [
    "# Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-breakdown",
   "metadata": {},
   "source": [
    "Deep learnign methods have achieved great success across several domains and tasks in the past few years. However, these supervised learning methods pose a great demands for large amount of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-falls",
   "metadata": {},
   "source": [
    "If we don't have enough labelled data, we can address these problems with:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-pattern",
   "metadata": {},
   "source": [
    "* Zero shot learning\n",
    "\n",
    "* One shot learning\n",
    "\n",
    "* few shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-lyric",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import sample\n",
    "\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import spatial\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-italy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/puneet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/puneet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/puneet/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#evalution metrics\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#linear algebra,data preprocessing,Csv files\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#for data cleaning\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#for feature selection\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#for classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#model selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120000, 3), (7600, 3))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['Title'] + \"  \" + df_train['Description']\n",
    "df_test['text']  = df_test['Title'] + \" \" + df_test['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['Title','Description'],1, inplace=True)\n",
    "df_test.drop(['Title','Description'],1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {1:'World News', 2:'Sports News', 3:'Business News', 4:'Science-Technology News'}\n",
    "\n",
    "df_train['category'] = df_train['Class Index'].map(categories)\n",
    "df_test['category'] = df_test['Class Index'].map(categories)\n",
    "\n",
    "df_train = df_train.drop(columns=['Class Index'])\n",
    "df_test = df_test.drop(columns=['Class Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-kelly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['World News', 'Sports News', 'Business News', 'Science-Technology News']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(categories.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-bookmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       category\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...  Business News\n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...  Business News\n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...  Business News\n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...  Business News\n",
       "4  Oil prices soar to all-time record, posing new...  Business News"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-negotiation",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_punc(text):\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "#normalizing case\n",
    "\n",
    "def normalize(text):        \n",
    "    lower_case = text.lower()\n",
    "    tokens=word_tokenize(lower_case)\n",
    "    return (\" \".join(tokens)).strip()\n",
    "\n",
    "\n",
    "nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
    "def remove_stop(text):        \n",
    "    word_list=[word for word in text.split() if word not in nltk_stop_words]\n",
    "    return \" \".join(word_list)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemma(text): \n",
    "    import pdb\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    return \" \".join(lemmas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].apply(remove_punc,1)\n",
    "df_test['text'] = df_test['text'].apply(remove_punc,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-laser",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def pipelinize(function, active=True):\n",
    "    def list_comprehend_a_function(list_or_series, active=True):\n",
    "        if active:\n",
    "            return [function(i) for i in list_or_series]\n",
    "        else: # if it's not active, just pass it right back\n",
    "            return list_or_series\n",
    "    return FunctionTransformer(list_comprehend_a_function, validate=False, kw_args={'active':active})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processing = make_pipeline(\n",
    "    *[ pipelinize(f) for f in [remove_punc,normalize, remove_stop, lemma]],\n",
    "    CountVectorizer(), \n",
    "    TfidfTransformer())\n",
    "\n",
    "\n",
    "pre_processing = make_column_transformer(\n",
    "    (text_processing, 'text'),\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-holiday",
   "metadata": {},
   "source": [
    "# Model \n",
    "\n",
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-armstrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('pipeline',\n",
       "                                                  Pipeline(steps=[('functiontransformer-1',\n",
       "                                                                   FunctionTransformer(func=<function pipelinize.<locals>.list_comprehend_a_function at 0x1e1500a60>,\n",
       "                                                                                       kw_args={'active': True})),\n",
       "                                                                  ('functiontransformer-2',\n",
       "                                                                   FunctionTransformer(func=<function pipelinize.<locals>.list_comprehend_a_function at...\n",
       "                                                                   FunctionTransformer(func=<function pipelinize.<locals>.list_comprehend_a_function at 0x1e26dd9d0>,\n",
       "                                                                                       kw_args={'active': True})),\n",
       "                                                                  ('functiontransformer-4',\n",
       "                                                                   FunctionTransformer(func=<function pipelinize.<locals>.list_comprehend_a_function at 0x1e26ddaf0>,\n",
       "                                                                                       kw_args={'active': True})),\n",
       "                                                                  ('countvectorizer',\n",
       "                                                                   CountVectorizer()),\n",
       "                                                                  ('tfidftransformer',\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  'text')])),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    pre_processing, \n",
    "     MultinomialNB()\n",
    ")\n",
    "model.fit(df_train, df_train.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_category = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          Business News       0.86      0.86      0.86      1900\n",
      "Science-Technology News       0.88      0.87      0.88      1900\n",
      "            Sports News       0.95      0.98      0.96      1900\n",
      "             World News       0.91      0.89      0.90      1900\n",
      "\n",
      "               accuracy                           0.90      7600\n",
      "              macro avg       0.90      0.90      0.90      7600\n",
      "           weighted avg       0.90      0.90      0.90      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.category,predicted_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-royal",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-digest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('pipeline',\n",
       "                                                  Pipeline(steps=[('functiontransformer-1',\n",
       "                                                                   FunctionTransformer(func=<function pipelinize.<locals>.list_comprehend_a_function at 0x1e1500a60>,\n",
       "                                                                                       kw_args={'active': True})),\n",
       "                                                                  ('functiontransformer-2',\n",
       "                                                                   FunctionTransformer(func=<function pipelinize.<locals>.list_comprehend_a_function at...\n",
       "                                                                   FunctionTransformer(func=<function pipelinize.<locals>.list_comprehend_a_function at 0x1e26dd9d0>,\n",
       "                                                                                       kw_args={'active': True})),\n",
       "                                                                  ('functiontransformer-4',\n",
       "                                                                   FunctionTransformer(func=<function pipelinize.<locals>.list_comprehend_a_function at 0x1e26ddaf0>,\n",
       "                                                                                       kw_args={'active': True})),\n",
       "                                                                  ('countvectorizer',\n",
       "                                                                   CountVectorizer()),\n",
       "                                                                  ('tfidftransformer',\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  'text')])),\n",
       "                ('sgdclassifier', SGDClassifier(alpha=0.001, random_state=42))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    pre_processing, \n",
    "     SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3,random_state=42)\n",
    ")\n",
    "model.fit(df_train, df_train.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_category = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          Business News       0.86      0.83      0.85      1900\n",
      "Science-Technology News       0.88      0.83      0.85      1900\n",
      "            Sports News       0.88      0.98      0.93      1900\n",
      "             World News       0.90      0.88      0.89      1900\n",
      "\n",
      "               accuracy                           0.88      7600\n",
      "              macro avg       0.88      0.88      0.88      7600\n",
      "           weighted avg       0.88      0.88      0.88      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.category,predicted_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-secretary",
   "metadata": {},
   "source": [
    "# Training a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import TREC_6\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.models.text_classification_model import TARSClassifier\n",
    "from flair.data import Sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flair_dataset(row):\n",
    "    return Sentence(row['text']).add_label('news',row['category'])\n",
    "\n",
    "res_train = df_train.apply(create_flair_dataset,1)\n",
    "res_test = df_test.apply(create_flair_dataset,1)\n",
    "\n",
    "corpus = Corpus(train = res_train.values.tolist(), test = res_test.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-interview",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-passenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"Carlyle Looks Toward Commercial Aerospace Reuters Reuters Private investment firm Carlyle Groupwhich has a reputation for making welltimed and occasionallycontroversial plays in the defense industry has quietly placedits bets on another part of the market\"   [− Tokens: 35  − Sentence-Labels: {'news': [Business News (1.0)]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'news'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    # FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
    "document_embeddings = DocumentRNNEmbeddings(embedding_types, hidden_size=256)\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "\n",
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# 7. start the training\n",
    "trainer.train('resources/taggers/trec',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassifier.load('resources/taggers/trec/final-model.pt')\n",
    "\n",
    "# create example sentence\n",
    "sentence = Sentence('Who built the Eiffel Tower ?')\n",
    "\n",
    "# predict class and print\n",
    "classifier.predict(sentence)\n",
    "\n",
    "print(sentence.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-columbia",
   "metadata": {},
   "source": [
    "# Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 20:31:27,381 loading file /Users/puneet/.flair/models/tars-base-v8.pt\n",
      "init TARS\n"
     ]
    }
   ],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "# 1. load base TARS\n",
    "tars = TARSClassifier.load('tars-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_to_predict = 100\n",
    "\n",
    "sample_df_test = df_test.sample(n=examples_to_predict)\n",
    "#sample_df_test = df_test\n",
    "\n",
    "def predict(row):\n",
    "    sentence = Sentence(row['text'])\n",
    "    tars.predict_zero_shot(sentence, list(categories.values()))\n",
    "    try:\n",
    "        row['predict'] = sentence.get_labels()[0].value\n",
    "    except:\n",
    "        row['predict'] = \"\"\n",
    "    return row\n",
    "\n",
    "sample_df_test_pred = sample_df_test.apply(predict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-footage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>Taiwans Leader Urges China to Begin Talks AP A...</td>\n",
       "      <td>World News</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>Colgate Profit Falls on Higher Costs  NEW YORK...</td>\n",
       "      <td>Business News</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>UPDATE Sons Of Gwalia In Administration On Hed...</td>\n",
       "      <td>Business News</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>Latham stands by Bali claims candidate Federal...</td>\n",
       "      <td>World News</td>\n",
       "      <td>World News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>Analysts See PostStern Ripple Effect Howard St...</td>\n",
       "      <td>Business News</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>Pantano replaced by Glock Jordan have terminat...</td>\n",
       "      <td>Sports News</td>\n",
       "      <td>Sports News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>US consumers unaware of spyware The findings c...</td>\n",
       "      <td>Business News</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>Asian Shares Hit by Metals Tumble Oil Reuters ...</td>\n",
       "      <td>Business News</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>Favre Does It Again With the Texans nursing a ...</td>\n",
       "      <td>Sports News</td>\n",
       "      <td>Sports News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>Merck Shares Drop on Report of Documents About...</td>\n",
       "      <td>Business News</td>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       category  \\\n",
       "3518  Taiwans Leader Urges China to Begin Talks AP A...     World News   \n",
       "4158  Colgate Profit Falls on Higher Costs  NEW YORK...  Business News   \n",
       "895   UPDATE Sons Of Gwalia In Administration On Hed...  Business News   \n",
       "2309  Latham stands by Bali claims candidate Federal...     World News   \n",
       "3335  Analysts See PostStern Ripple Effect Howard St...  Business News   \n",
       "...                                                 ...            ...   \n",
       "2250  Pantano replaced by Glock Jordan have terminat...    Sports News   \n",
       "3968  US consumers unaware of spyware The findings c...  Business News   \n",
       "3763  Asian Shares Hit by Metals Tumble Oil Reuters ...  Business News   \n",
       "6225  Favre Does It Again With the Texans nursing a ...    Sports News   \n",
       "4962  Merck Shares Drop on Report of Documents About...  Business News   \n",
       "\n",
       "            predict  \n",
       "3518                 \n",
       "4158  Business News  \n",
       "895   Business News  \n",
       "2309     World News  \n",
       "3335  Business News  \n",
       "...             ...  \n",
       "2250    Sports News  \n",
       "3968                 \n",
       "3763  Business News  \n",
       "6225    Sports News  \n",
       "4962  Business News  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-theology",
   "metadata": {},
   "source": [
    "It got 73 % accuracy. SVM had 50% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                              0.00      0.00      0.00         0\n",
      "          Business News       0.89      0.91      0.90        34\n",
      "Science-Technology News       1.00      0.29      0.44        21\n",
      "            Sports News       1.00      1.00      1.00        22\n",
      "             World News       1.00      0.61      0.76        23\n",
      "\n",
      "               accuracy                           0.73       100\n",
      "              macro avg       0.78      0.56      0.62       100\n",
      "           weighted avg       0.96      0.73      0.79       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sample_df_test_pred.category,sample_df_test_pred.predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-bottle",
   "metadata": {},
   "source": [
    "# Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-way , K Samples training\n",
    "\n",
    "def get_model(classes = list(categories.values()), k=3):\n",
    "\n",
    "    # 1. load base TARS\n",
    "    tars = TARSClassifier.load('tars-base')\n",
    "\n",
    "    \n",
    "    # get examples from training data\n",
    "    sample_df = df_train.groupby('category').apply(lambda x: x.sample(n=k)).sample(frac=1).reset_index(drop=True)\n",
    "    print(sample_df)\n",
    "    print(\"size of training data is {}\".format(sample_df.shape))\n",
    "    \n",
    "    sample_res_train = sample_df.apply(create_flair_dataset,1)\n",
    "    sample_res_test = sample_df.apply(create_flair_dataset,1)\n",
    "\n",
    "    new_corpus = Corpus(train = sample_res_train.values.tolist(), test = sample_res_test.values.tolist())\n",
    "    print(\"Corpus ready to load: Train {} , Test: {} \".format(len(new_corpus.train), len(new_corpus.test)))\n",
    "    \n",
    "    # 3. make the model aware of the desired set of labels from the new corpus\n",
    "    tars.add_and_switch_to_new_task( \"NEWS_CLASSIFICATION\",\n",
    "                                     label_dictionary=new_corpus.make_label_dictionary())\n",
    "    # 4. initialize the text classifier trainer\n",
    "    trainer = ModelTrainer(tars, new_corpus)\n",
    "\n",
    "    # 5. start the training\n",
    "    trainer.train(base_path='resources/taggers/go_emotions', # path to store the model artifacts\n",
    "              learning_rate=0.02, # use very small learning rate\n",
    "              mini_batch_size=16,\n",
    "              mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "              max_epochs=10, # terminate after 10 epochs\n",
    "              )\n",
    "    \n",
    "    return tars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-force",
   "metadata": {},
   "source": [
    "# K = 1\n",
    "\n",
    "Number of examples per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-klein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:01:19,716 loading file /Users/puneet/.flair/models/tars-base-v8.pt\n",
      "init TARS\n",
      "                                                text                 category\n",
      "0  Russian Ministries Start Agreeing to Kyoto App...               World News\n",
      "1  Team of Mystery  Many around the NFL say they ...              Sports News\n",
      "2  Voq smartphone arrives in US  With the economy...  Science-Technology News\n",
      "3  Bush stands up for strong dollar  President Ge...            Business News\n",
      "size of training data is (4, 2)\n",
      "Corpus ready to load: Train 4 , Test: 4 \n",
      "2021-03-13 21:01:23,462 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 16735.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:01:23,466 [b'World News', b'Sports News', b'Science-Technology News', b'Business News']\n",
      "2021-03-13 21:01:23,468 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:23,470 Model: \"TARSClassifier(\n",
      "  (document_embeddings): None\n",
      "  (decoder): None\n",
      "  (loss_function): None\n",
      "  (tars_model): TextClassifier(\n",
      "    (document_embeddings): TransformerDocumentEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (loss_function): CrossEntropyLoss()\n",
      "  )\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-03-13 21:01:23,471 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:23,472 Corpus: \"Corpus: 4 train + 0 dev + 4 test sentences\"\n",
      "2021-03-13 21:01:23,473 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:23,474 Parameters:\n",
      "2021-03-13 21:01:23,474  - learning_rate: \"0.02\"\n",
      "2021-03-13 21:01:23,475  - mini_batch_size: \"16\"\n",
      "2021-03-13 21:01:23,476  - patience: \"3\"\n",
      "2021-03-13 21:01:23,477  - anneal_factor: \"0.5\"\n",
      "2021-03-13 21:01:23,477  - max_epochs: \"10\"\n",
      "2021-03-13 21:01:23,478  - shuffle: \"True\"\n",
      "2021-03-13 21:01:23,479  - train_with_dev: \"False\"\n",
      "2021-03-13 21:01:23,480  - batch_growth_annealing: \"False\"\n",
      "2021-03-13 21:01:23,481 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:23,482 Model training base path: \"resources/taggers/go_emotions\"\n",
      "2021-03-13 21:01:23,483 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:23,484 Device: cpu\n",
      "2021-03-13 21:01:23,485 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:23,485 Embeddings storage mode: cpu\n",
      "2021-03-13 21:01:23,491 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:01:25,305 epoch 1 - iter 1/1 - loss 0.72547483 - samples/sec: 9.24 - lr: 0.020000\n",
      "2021-03-13 21:01:25,307 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:25,308 EPOCH 1 done: loss 0.7255 - lr 0.0200000\n",
      "2021-03-13 21:01:25,309 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:01:26,089 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:27,934 epoch 2 - iter 1/1 - loss 0.10859243 - samples/sec: 8.96 - lr: 0.020000\n",
      "2021-03-13 21:01:27,935 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:27,936 EPOCH 2 done: loss 0.1086 - lr 0.0200000\n",
      "2021-03-13 21:01:27,937 BAD EPOCHS (no improvement): 1\n",
      "2021-03-13 21:01:27,938 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:30,100 epoch 3 - iter 1/1 - loss 0.03134261 - samples/sec: 7.68 - lr: 0.020000\n",
      "2021-03-13 21:01:30,102 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:30,102 EPOCH 3 done: loss 0.0313 - lr 0.0200000\n",
      "2021-03-13 21:01:30,103 BAD EPOCHS (no improvement): 2\n",
      "2021-03-13 21:01:30,104 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:32,078 epoch 4 - iter 1/1 - loss 0.00682161 - samples/sec: 8.38 - lr: 0.020000\n",
      "2021-03-13 21:01:32,079 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:32,080 EPOCH 4 done: loss 0.0068 - lr 0.0200000\n",
      "2021-03-13 21:01:32,081 BAD EPOCHS (no improvement): 3\n",
      "2021-03-13 21:01:32,082 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:34,077 epoch 5 - iter 1/1 - loss 0.02493999 - samples/sec: 8.30 - lr: 0.020000\n",
      "2021-03-13 21:01:34,078 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:34,079 EPOCH 5 done: loss 0.0249 - lr 0.0200000\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-02.\n",
      "2021-03-13 21:01:34,080 BAD EPOCHS (no improvement): 4\n",
      "2021-03-13 21:01:34,082 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:35,986 epoch 6 - iter 1/1 - loss 0.00624902 - samples/sec: 8.70 - lr: 0.010000\n",
      "2021-03-13 21:01:35,987 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:35,988 EPOCH 6 done: loss 0.0062 - lr 0.0100000\n",
      "2021-03-13 21:01:35,989 BAD EPOCHS (no improvement): 1\n",
      "2021-03-13 21:01:35,990 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:37,974 epoch 7 - iter 1/1 - loss 0.01262744 - samples/sec: 8.34 - lr: 0.010000\n",
      "2021-03-13 21:01:37,976 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:37,977 EPOCH 7 done: loss 0.0126 - lr 0.0100000\n",
      "2021-03-13 21:01:37,977 BAD EPOCHS (no improvement): 2\n",
      "2021-03-13 21:01:37,979 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:40,008 epoch 8 - iter 1/1 - loss 0.00636292 - samples/sec: 8.15 - lr: 0.010000\n",
      "2021-03-13 21:01:40,010 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:40,011 EPOCH 8 done: loss 0.0064 - lr 0.0100000\n",
      "2021-03-13 21:01:40,012 BAD EPOCHS (no improvement): 3\n",
      "2021-03-13 21:01:40,013 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:42,045 epoch 9 - iter 1/1 - loss 0.00723257 - samples/sec: 8.15 - lr: 0.010000\n",
      "2021-03-13 21:01:42,047 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:42,048 EPOCH 9 done: loss 0.0072 - lr 0.0100000\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0000e-03.\n",
      "2021-03-13 21:01:42,049 BAD EPOCHS (no improvement): 4\n",
      "2021-03-13 21:01:42,050 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:44,059 epoch 10 - iter 1/1 - loss 0.00457435 - samples/sec: 8.25 - lr: 0.005000\n",
      "2021-03-13 21:01:44,061 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:44,062 EPOCH 10 done: loss 0.0046 - lr 0.0050000\n",
      "2021-03-13 21:01:44,063 BAD EPOCHS (no improvement): 1\n",
      "2021-03-13 21:01:44,806 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:01:44,807 Testing using best model ...\n",
      "2021-03-13 21:01:44,808 loading file resources/taggers/go_emotions/best-model.pt\n",
      "init TARS\n",
      "2021-03-13 21:01:48,394 \t1.0\n",
      "2021-03-13 21:01:48,395 \n",
      "Results:\n",
      "- F-score (micro) 1.0\n",
      "- F-score (macro) 1.0\n",
      "- Accuracy 1.0\n",
      "\n",
      "By class:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             World News     1.0000    1.0000    1.0000         1\n",
      "            Sports News     1.0000    1.0000    1.0000         1\n",
      "Science-Technology News     1.0000    1.0000    1.0000         1\n",
      "          Business News     1.0000    1.0000    1.0000         1\n",
      "\n",
      "              micro avg     1.0000    1.0000    1.0000         4\n",
      "              macro avg     1.0000    1.0000    1.0000         4\n",
      "           weighted avg     1.0000    1.0000    1.0000         4\n",
      "            samples avg     1.0000    1.0000    1.0000         4\n",
      "\n",
      "2021-03-13 21:01:48,396 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tars = get_model(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_test_pred = sample_df_test.apply(predict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-gospel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                              0.00      0.00      0.00         0\n",
      "          Business News       0.88      0.88      0.88        34\n",
      "Science-Technology News       0.88      0.33      0.48        21\n",
      "            Sports News       1.00      0.95      0.98        22\n",
      "             World News       0.83      0.83      0.83        23\n",
      "\n",
      "               accuracy                           0.77       100\n",
      "              macro avg       0.72      0.60      0.63       100\n",
      "           weighted avg       0.89      0.77      0.81       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sample_df_test_pred.category,sample_df_test_pred.predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-business",
   "metadata": {},
   "source": [
    "# K= 2\n",
    "\n",
    "Number of examples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:06:53,375 loading file /Users/puneet/.flair/models/tars-base-v8.pt\n",
      "init TARS\n",
      "                                                text                 category\n",
      "0  Zafi worm proves a holiday pest  The massmaili...  Science-Technology News\n",
      "1  Former Steelers Maine player Strzelczyk dies a...              Sports News\n",
      "2  Grower Suggests Opening Your Mind to More Open...            Business News\n",
      "3   Americans and Briton Are Kidnapped by Rebels ...               World News\n",
      "4  Mars rovers roll on with new funding  NASA has...  Science-Technology News\n",
      "5   Former Kmart Execs Charged with Fraud   WASHI...            Business News\n",
      "6  Palestinian officials rush to bedside of ailin...               World News\n",
      "7  Lehmann howlers rob Arsenal  Lehmann who was a...              Sports News\n",
      "size of training data is (8, 2)\n",
      "Corpus ready to load: Train 7 , Test: 8 \n",
      "2021-03-13 21:06:57,360 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 16894.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:06:57,364 [b'Science-Technology News', b'Sports News', b'Business News', b'World News']\n",
      "2021-03-13 21:06:57,366 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:06:57,369 Model: \"TARSClassifier(\n",
      "  (document_embeddings): None\n",
      "  (decoder): None\n",
      "  (loss_function): None\n",
      "  (tars_model): TextClassifier(\n",
      "    (document_embeddings): TransformerDocumentEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (loss_function): CrossEntropyLoss()\n",
      "  )\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-03-13 21:06:57,371 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:06:57,372 Corpus: \"Corpus: 7 train + 1 dev + 8 test sentences\"\n",
      "2021-03-13 21:06:57,373 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:06:57,373 Parameters:\n",
      "2021-03-13 21:06:57,374  - learning_rate: \"0.02\"\n",
      "2021-03-13 21:06:57,375  - mini_batch_size: \"16\"\n",
      "2021-03-13 21:06:57,376  - patience: \"3\"\n",
      "2021-03-13 21:06:57,376  - anneal_factor: \"0.5\"\n",
      "2021-03-13 21:06:57,377  - max_epochs: \"10\"\n",
      "2021-03-13 21:06:57,378  - shuffle: \"True\"\n",
      "2021-03-13 21:06:57,379  - train_with_dev: \"False\"\n",
      "2021-03-13 21:06:57,379  - batch_growth_annealing: \"False\"\n",
      "2021-03-13 21:06:57,380 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:06:57,381 Model training base path: \"resources/taggers/go_emotions\"\n",
      "2021-03-13 21:06:57,382 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:06:57,383 Device: cpu\n",
      "2021-03-13 21:06:57,384 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:06:57,385 Embeddings storage mode: cpu\n",
      "2021-03-13 21:06:57,390 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:07:01,372 epoch 1 - iter 1/1 - loss 0.00358509 - samples/sec: 4.09 - lr: 0.020000\n",
      "2021-03-13 21:07:01,374 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:01,375 EPOCH 1 done: loss 0.0036 - lr 0.0200000\n",
      "2021-03-13 21:07:01,533 DEV : loss 0.02817917801439762 - score 1.0\n",
      "2021-03-13 21:07:01,534 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:02,279 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:07,998 epoch 2 - iter 1/1 - loss 0.00418822 - samples/sec: 2.83 - lr: 0.020000\n",
      "2021-03-13 21:07:08,000 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:08,001 EPOCH 2 done: loss 0.0042 - lr 0.0200000\n",
      "2021-03-13 21:07:08,167 DEV : loss 0.024391956627368927 - score 1.0\n",
      "2021-03-13 21:07:08,168 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:08,925 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:14,309 epoch 3 - iter 1/1 - loss 0.00569353 - samples/sec: 3.01 - lr: 0.020000\n",
      "2021-03-13 21:07:14,311 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:14,311 EPOCH 3 done: loss 0.0057 - lr 0.0200000\n",
      "2021-03-13 21:07:14,599 DEV : loss 0.021887432783842087 - score 1.0\n",
      "2021-03-13 21:07:14,600 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:15,436 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:19,882 epoch 4 - iter 1/1 - loss 0.00308452 - samples/sec: 3.65 - lr: 0.020000\n",
      "2021-03-13 21:07:19,884 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:19,885 EPOCH 4 done: loss 0.0031 - lr 0.0200000\n",
      "2021-03-13 21:07:20,078 DEV : loss 0.020752161741256714 - score 1.0\n",
      "2021-03-13 21:07:20,080 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:20,852 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:25,231 epoch 5 - iter 1/1 - loss 0.00064482 - samples/sec: 3.71 - lr: 0.020000\n",
      "2021-03-13 21:07:25,233 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:25,234 EPOCH 5 done: loss 0.0006 - lr 0.0200000\n",
      "2021-03-13 21:07:25,511 DEV : loss 0.02024073153734207 - score 1.0\n",
      "2021-03-13 21:07:25,512 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:26,351 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:30,861 epoch 6 - iter 1/1 - loss 0.00080775 - samples/sec: 3.61 - lr: 0.020000\n",
      "2021-03-13 21:07:30,863 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:30,864 EPOCH 6 done: loss 0.0008 - lr 0.0200000\n",
      "2021-03-13 21:07:31,063 DEV : loss 0.019914690405130386 - score 1.0\n",
      "2021-03-13 21:07:31,064 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:31,821 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:36,379 epoch 7 - iter 1/1 - loss 0.00040723 - samples/sec: 3.55 - lr: 0.020000\n",
      "2021-03-13 21:07:36,381 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:36,382 EPOCH 7 done: loss 0.0004 - lr 0.0200000\n",
      "2021-03-13 21:07:36,578 DEV : loss 0.019784875214099884 - score 1.0\n",
      "2021-03-13 21:07:36,579 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:37,457 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:42,211 epoch 8 - iter 1/1 - loss 0.00075786 - samples/sec: 3.41 - lr: 0.020000\n",
      "2021-03-13 21:07:42,213 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:42,214 EPOCH 8 done: loss 0.0008 - lr 0.0200000\n",
      "2021-03-13 21:07:42,408 DEV : loss 0.0191633440554142 - score 1.0\n",
      "2021-03-13 21:07:42,409 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:43,213 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:48,092 epoch 9 - iter 1/1 - loss 0.00018994 - samples/sec: 3.32 - lr: 0.020000\n",
      "2021-03-13 21:07:48,093 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:48,094 EPOCH 9 done: loss 0.0002 - lr 0.0200000\n",
      "2021-03-13 21:07:48,297 DEV : loss 0.018932759761810303 - score 1.0\n",
      "2021-03-13 21:07:48,298 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:49,056 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:53,592 epoch 10 - iter 1/1 - loss 0.00084482 - samples/sec: 3.57 - lr: 0.020000\n",
      "2021-03-13 21:07:53,593 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:53,594 EPOCH 10 done: loss 0.0008 - lr 0.0200000\n",
      "2021-03-13 21:07:53,805 DEV : loss 0.018688632175326347 - score 1.0\n",
      "2021-03-13 21:07:53,806 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:07:55,371 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:07:55,372 Testing using best model ...\n",
      "2021-03-13 21:07:55,374 loading file resources/taggers/go_emotions/best-model.pt\n",
      "init TARS\n",
      "2021-03-13 21:08:00,278 \t1.0\n",
      "2021-03-13 21:08:00,279 \n",
      "Results:\n",
      "- F-score (micro) 1.0\n",
      "- F-score (macro) 1.0\n",
      "- Accuracy 1.0\n",
      "\n",
      "By class:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "Science-Technology News     1.0000    1.0000    1.0000         2\n",
      "            Sports News     1.0000    1.0000    1.0000         2\n",
      "          Business News     1.0000    1.0000    1.0000         2\n",
      "             World News     1.0000    1.0000    1.0000         2\n",
      "\n",
      "              micro avg     1.0000    1.0000    1.0000         8\n",
      "              macro avg     1.0000    1.0000    1.0000         8\n",
      "           weighted avg     1.0000    1.0000    1.0000         8\n",
      "            samples avg     1.0000    1.0000    1.0000         8\n",
      "\n",
      "2021-03-13 21:08:00,280 ----------------------------------------------------------------------------------------------------\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                              0.00      0.00      0.00         0\n",
      "          Business News       0.89      0.91      0.90        34\n",
      "Science-Technology News       0.89      0.38      0.53        21\n",
      "            Sports News       1.00      1.00      1.00        22\n",
      "             World News       0.95      0.78      0.86        23\n",
      "\n",
      "               accuracy                           0.79       100\n",
      "              macro avg       0.74      0.62      0.66       100\n",
      "           weighted avg       0.93      0.79      0.83       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tars = get_model(k=2)\n",
    "sample_df_test_pred = sample_df_test.apply(predict, 1)\n",
    "print(classification_report(sample_df_test_pred.category,sample_df_test_pred.predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-engineer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:09:46,329 loading file /Users/puneet/.flair/models/tars-base-v8.pt\n",
      "init TARS\n",
      "                                                 text                 category\n",
      "0   CL Preview  Man UnitedSparta Prague  United ho...              Sports News\n",
      "1   Beslan children return to school  Schools in t...               World News\n",
      "2   Amnesty China Arrests Jails Human Rights Defen...               World News\n",
      "3   Rockies Pitcher Frets Health Not Baseball AP  ...              Sports News\n",
      "4   Starbucks Profit Climbs Extra Week Helps Reute...            Business News\n",
      "5   In Spain a missing link  NEW YORK Scientists i...  Science-Technology News\n",
      "6   Metcalfe Allen back ZigBee startup  Ember a st...  Science-Technology News\n",
      "7   Powell to say Thursday if Darfur deaths are ge...               World News\n",
      "8   When dreamers wield hammers  By day Lorenzo Ma...            Business News\n",
      "9   Electronic Voting Raises New Issues  Touted as...  Science-Technology News\n",
      "10  Police ID Officer in Red Sox Fan Death AP  AP ...              Sports News\n",
      "11  Florida Examines Higher Insurance Deductibles ...            Business News\n",
      "size of training data is (12, 2)\n",
      "Corpus ready to load: Train 11 , Test: 12 \n",
      "2021-03-13 21:09:50,047 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 29483.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:09:50,050 [b'Sports News', b'World News', b'Business News', b'Science-Technology News']\n",
      "2021-03-13 21:09:50,052 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:09:50,055 Model: \"TARSClassifier(\n",
      "  (document_embeddings): None\n",
      "  (decoder): None\n",
      "  (loss_function): None\n",
      "  (tars_model): TextClassifier(\n",
      "    (document_embeddings): TransformerDocumentEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (loss_function): CrossEntropyLoss()\n",
      "  )\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-03-13 21:09:50,056 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:09:50,058 Corpus: \"Corpus: 11 train + 1 dev + 12 test sentences\"\n",
      "2021-03-13 21:09:50,058 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:09:50,059 Parameters:\n",
      "2021-03-13 21:09:50,060  - learning_rate: \"0.02\"\n",
      "2021-03-13 21:09:50,061  - mini_batch_size: \"16\"\n",
      "2021-03-13 21:09:50,062  - patience: \"3\"\n",
      "2021-03-13 21:09:50,062  - anneal_factor: \"0.5\"\n",
      "2021-03-13 21:09:50,063  - max_epochs: \"10\"\n",
      "2021-03-13 21:09:50,064  - shuffle: \"True\"\n",
      "2021-03-13 21:09:50,065  - train_with_dev: \"False\"\n",
      "2021-03-13 21:09:50,066  - batch_growth_annealing: \"False\"\n",
      "2021-03-13 21:09:50,066 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:09:50,067 Model training base path: \"resources/taggers/go_emotions\"\n",
      "2021-03-13 21:09:50,068 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:09:50,069 Device: cpu\n",
      "2021-03-13 21:09:50,069 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:09:50,070 Embeddings storage mode: cpu\n",
      "2021-03-13 21:09:50,075 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:09:55,572 epoch 1 - iter 1/1 - loss 0.39624599 - samples/sec: 2.95 - lr: 0.020000\n",
      "2021-03-13 21:09:55,574 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:09:55,574 EPOCH 1 done: loss 0.3962 - lr 0.0200000\n",
      "2021-03-13 21:09:55,807 DEV : loss 0.01594771072268486 - score 1.0\n",
      "2021-03-13 21:09:55,808 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:09:56,583 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:03,876 epoch 2 - iter 1/1 - loss 0.02269825 - samples/sec: 2.22 - lr: 0.020000\n",
      "2021-03-13 21:10:03,879 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:03,880 EPOCH 2 done: loss 0.0227 - lr 0.0200000\n",
      "2021-03-13 21:10:04,061 DEV : loss 0.012076146900653839 - score 1.0\n",
      "2021-03-13 21:10:04,062 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:10:04,819 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:10,309 epoch 3 - iter 1/1 - loss 0.02986162 - samples/sec: 2.95 - lr: 0.020000\n",
      "2021-03-13 21:10:10,311 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:10,312 EPOCH 3 done: loss 0.0299 - lr 0.0200000\n",
      "2021-03-13 21:10:10,546 DEV : loss 0.005301790777593851 - score 1.0\n",
      "2021-03-13 21:10:10,548 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:10:11,321 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:17,305 epoch 4 - iter 1/1 - loss 0.00250828 - samples/sec: 2.70 - lr: 0.020000\n",
      "2021-03-13 21:10:17,307 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:17,308 EPOCH 4 done: loss 0.0025 - lr 0.0200000\n",
      "2021-03-13 21:10:17,509 DEV : loss 0.004070390947163105 - score 1.0\n",
      "2021-03-13 21:10:17,510 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:10:18,277 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:24,252 epoch 5 - iter 1/1 - loss 0.00314308 - samples/sec: 2.71 - lr: 0.020000\n",
      "2021-03-13 21:10:24,253 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:24,254 EPOCH 5 done: loss 0.0031 - lr 0.0200000\n",
      "2021-03-13 21:10:24,552 DEV : loss 0.0031809955835342407 - score 1.0\n",
      "2021-03-13 21:10:24,553 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:10:25,328 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:31,542 epoch 6 - iter 1/1 - loss 0.00259899 - samples/sec: 2.60 - lr: 0.020000\n",
      "2021-03-13 21:10:31,543 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:31,544 EPOCH 6 done: loss 0.0026 - lr 0.0200000\n",
      "2021-03-13 21:10:31,762 DEV : loss 0.002913933712989092 - score 1.0\n",
      "2021-03-13 21:10:31,763 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:10:32,626 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:38,263 epoch 7 - iter 1/1 - loss 0.00023606 - samples/sec: 2.87 - lr: 0.020000\n",
      "2021-03-13 21:10:38,264 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:38,265 EPOCH 7 done: loss 0.0002 - lr 0.0200000\n",
      "2021-03-13 21:10:38,475 DEV : loss 0.003407376352697611 - score 1.0\n",
      "2021-03-13 21:10:38,476 BAD EPOCHS (no improvement): 1\n",
      "2021-03-13 21:10:38,478 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:44,428 epoch 8 - iter 1/1 - loss 0.00161351 - samples/sec: 2.72 - lr: 0.020000\n",
      "2021-03-13 21:10:44,429 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:44,430 EPOCH 8 done: loss 0.0016 - lr 0.0200000\n",
      "2021-03-13 21:10:44,694 DEV : loss 0.00305991992354393 - score 1.0\n",
      "2021-03-13 21:10:44,696 BAD EPOCHS (no improvement): 2\n",
      "2021-03-13 21:10:44,698 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:50,666 epoch 9 - iter 1/1 - loss 0.00231428 - samples/sec: 2.71 - lr: 0.020000\n",
      "2021-03-13 21:10:50,668 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:50,669 EPOCH 9 done: loss 0.0023 - lr 0.0200000\n",
      "2021-03-13 21:10:50,978 DEV : loss 0.002760577015578747 - score 1.0\n",
      "2021-03-13 21:10:50,980 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:10:51,753 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:57,674 epoch 10 - iter 1/1 - loss 0.00141195 - samples/sec: 2.73 - lr: 0.020000\n",
      "2021-03-13 21:10:57,676 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:57,676 EPOCH 10 done: loss 0.0014 - lr 0.0200000\n",
      "2021-03-13 21:10:57,981 DEV : loss 0.0022951539140194654 - score 1.0\n",
      "2021-03-13 21:10:57,982 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:10:59,641 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:10:59,642 Testing using best model ...\n",
      "2021-03-13 21:10:59,644 loading file resources/taggers/go_emotions/best-model.pt\n",
      "init TARS\n",
      "2021-03-13 21:11:06,395 \t1.0\n",
      "2021-03-13 21:11:06,396 \n",
      "Results:\n",
      "- F-score (micro) 1.0\n",
      "- F-score (macro) 1.0\n",
      "- Accuracy 1.0\n",
      "\n",
      "By class:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Sports News     1.0000    1.0000    1.0000         3\n",
      "             World News     1.0000    1.0000    1.0000         3\n",
      "          Business News     1.0000    1.0000    1.0000         3\n",
      "Science-Technology News     1.0000    1.0000    1.0000         3\n",
      "\n",
      "              micro avg     1.0000    1.0000    1.0000        12\n",
      "              macro avg     1.0000    1.0000    1.0000        12\n",
      "           weighted avg     1.0000    1.0000    1.0000        12\n",
      "            samples avg     1.0000    1.0000    1.0000        12\n",
      "\n",
      "2021-03-13 21:11:06,397 ----------------------------------------------------------------------------------------------------\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                              0.00      0.00      0.00         0\n",
      "          Business News       0.91      0.91      0.91        34\n",
      "Science-Technology News       0.92      0.52      0.67        21\n",
      "            Sports News       1.00      1.00      1.00        22\n",
      "             World News       0.95      0.83      0.88        23\n",
      "\n",
      "               accuracy                           0.83       100\n",
      "              macro avg       0.76      0.65      0.69       100\n",
      "           weighted avg       0.94      0.83      0.87       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tars = get_model(k=3)\n",
    "sample_df_test_pred = sample_df_test.apply(predict, 1)\n",
    "print(classification_report(sample_df_test_pred.category,sample_df_test_pred.predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:12:03,709 loading file /Users/puneet/.flair/models/tars-base-v8.pt\n",
      "init TARS\n",
      "                                                 text                 category\n",
      "0   Hamas Israel behind Damascus bombing  The Pale...               World News\n",
      "1   Sprint to Cut  Jobs Reuters  Reuters  Sprint C...  Science-Technology News\n",
      "2   Former MVP Caminiti Dies of Heart Attack at  R...              Sports News\n",
      "3   As media darling Conte  pushing it  No one kno...              Sports News\n",
      "4   Google Investors Await the Dropping of  Millio...  Science-Technology News\n",
      "5   Euro Disney shareholders back capital increase...            Business News\n",
      "6   Polls show a tough fight PM  POLLS out today g...               World News\n",
      "7   Victorious Iraqi forces patrol Samarra  SAMARR...               World News\n",
      "8   Reborn WorldCom in search of  buyer  MCI the t...            Business News\n",
      "9   Eye on IT  Sometimes if you make believe somet...  Science-Technology News\n",
      "10  FDA Encourages Radio Tags on Drug Bottles  Via...  Science-Technology News\n",
      "11  Dashing former England midfielder Weller dies ...               World News\n",
      "12  Gold medalist Noguchi pondering future  ATHENS...              Sports News\n",
      "13  OPEC sees  million barrels per day demand drop...            Business News\n",
      "14  Toronto hostagetaker holds woman at gunpoint s...               World News\n",
      "15  Apple Expo Apple intros    iMac  Apple  senior...  Science-Technology News\n",
      "16  Aung San Suu Kyi still under house arrest  The...               World News\n",
      "17  Sony sets price date for PSPs Japan debut  The...  Science-Technology News\n",
      "18  Pew study Blogs busted out in   For blogs and ...  Science-Technology News\n",
      "19  XP  Gives Reasons to Switch to Linux Ziff Davi...  Science-Technology News\n",
      "20  China blocks Google news site  China has been ...               World News\n",
      "21  Cash America Places  Bet on Territory Swap  FO...            Business News\n",
      "22  Google launches new Web site for readers publi...  Science-Technology News\n",
      "23  Garciaparra still interested in Cubs  BASEBALL...              Sports News\n",
      "24  Performance not passion must be Lerner  streng...              Sports News\n",
      "25  US Air Reaches Giveback Deal with Pilots Reute...            Business News\n",
      "26  Sixers Robinson Dalembert Get Demotions AP  AP...              Sports News\n",
      "27  Astros ride Clemens homers to win  The Houston...              Sports News\n",
      "28  Strong quakes rattle Japan  A series of powerf...               World News\n",
      "29  Search Wars Google Snap Amazon Arm for Battle ...  Science-Technology News\n",
      "30  IBM settles pension suit take charge  Internat...            Business News\n",
      "31  Newfoundlands flag flap with Ottawa raises ire...               World News\n",
      "32  Barnes   Noble Posts Lower Profit Reuters  Reu...            Business News\n",
      "33  A M Aims to Dodge Another Oklahoma Beating AP ...              Sports News\n",
      "34  Before the Bell Atherogenics Up  Pct   NEW YOR...            Business News\n",
      "35  Rossi shapes up to new challenges to remain Mo...              Sports News\n",
      "36  OPEC likely to push to tighten supply  OPEC oi...            Business News\n",
      "37  Kidde Opens Books to United Technologies  Kidd...            Business News\n",
      "38  Wenger fined for his wicked tongue will not ap...              Sports News\n",
      "39  France Hopes Iraq Hostages Will Be Freed Soon ...               World News\n",
      "size of training data is (40, 2)\n",
      "Corpus ready to load: Train 36 , Test: 40 \n",
      "2021-03-13 21:12:07,684 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:00<00:00, 44340.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:12:07,689 [b'World News', b'Sports News', b'Science-Technology News', b'Business News']\n",
      "2021-03-13 21:12:07,691 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:12:07,694 Model: \"TARSClassifier(\n",
      "  (document_embeddings): None\n",
      "  (decoder): None\n",
      "  (loss_function): None\n",
      "  (tars_model): TextClassifier(\n",
      "    (document_embeddings): TransformerDocumentEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (loss_function): CrossEntropyLoss()\n",
      "  )\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-03-13 21:12:07,695 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:12:07,696 Corpus: \"Corpus: 36 train + 4 dev + 40 test sentences\"\n",
      "2021-03-13 21:12:07,697 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:12:07,698 Parameters:\n",
      "2021-03-13 21:12:07,699  - learning_rate: \"0.02\"\n",
      "2021-03-13 21:12:07,699  - mini_batch_size: \"16\"\n",
      "2021-03-13 21:12:07,700  - patience: \"3\"\n",
      "2021-03-13 21:12:07,701  - anneal_factor: \"0.5\"\n",
      "2021-03-13 21:12:07,702  - max_epochs: \"10\"\n",
      "2021-03-13 21:12:07,702  - shuffle: \"True\"\n",
      "2021-03-13 21:12:07,703  - train_with_dev: \"False\"\n",
      "2021-03-13 21:12:07,704  - batch_growth_annealing: \"False\"\n",
      "2021-03-13 21:12:07,705 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:12:07,705 Model training base path: \"resources/taggers/go_emotions\"\n",
      "2021-03-13 21:12:07,706 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:12:07,707 Device: cpu\n",
      "2021-03-13 21:12:07,708 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:12:07,709 Embeddings storage mode: cpu\n",
      "2021-03-13 21:12:07,715 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:12:17,670 epoch 1 - iter 1/3 - loss 0.69966990 - samples/sec: 1.62 - lr: 0.020000\n",
      "2021-03-13 21:12:28,389 epoch 1 - iter 2/3 - loss 0.38328363 - samples/sec: 1.49 - lr: 0.020000\n",
      "2021-03-13 21:12:31,193 epoch 1 - iter 3/3 - loss 0.25881933 - samples/sec: 5.71 - lr: 0.020000\n",
      "2021-03-13 21:12:31,195 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:12:31,196 EPOCH 1 done: loss 0.2588 - lr 0.0200000\n",
      "2021-03-13 21:12:32,493 DEV : loss 0.19850775599479675 - score 1.0\n",
      "2021-03-13 21:12:32,495 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:12:33,273 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:12:47,065 epoch 2 - iter 1/3 - loss 0.54060596 - samples/sec: 1.17 - lr: 0.020000\n",
      "2021-03-13 21:12:55,651 epoch 2 - iter 2/3 - loss 0.27841292 - samples/sec: 1.86 - lr: 0.020000\n",
      "2021-03-13 21:12:57,779 epoch 2 - iter 3/3 - loss 0.19700600 - samples/sec: 7.52 - lr: 0.020000\n",
      "2021-03-13 21:12:57,781 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:12:57,782 EPOCH 2 done: loss 0.1970 - lr 0.0200000\n",
      "2021-03-13 21:12:59,247 DEV : loss 0.3308909833431244 - score 1.0\n",
      "2021-03-13 21:12:59,249 BAD EPOCHS (no improvement): 1\n",
      "2021-03-13 21:12:59,251 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:13:09,919 epoch 3 - iter 1/3 - loss 0.00706016 - samples/sec: 1.51 - lr: 0.020000\n",
      "2021-03-13 21:13:18,533 epoch 3 - iter 2/3 - loss 0.00697318 - samples/sec: 1.86 - lr: 0.020000\n",
      "2021-03-13 21:13:21,078 epoch 3 - iter 3/3 - loss 0.03006679 - samples/sec: 6.29 - lr: 0.020000\n",
      "2021-03-13 21:13:21,079 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:13:21,080 EPOCH 3 done: loss 0.0301 - lr 0.0200000\n",
      "2021-03-13 21:13:22,325 DEV : loss 0.2269955575466156 - score 1.0\n",
      "2021-03-13 21:13:22,326 BAD EPOCHS (no improvement): 2\n",
      "2021-03-13 21:13:22,328 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:13:31,537 epoch 4 - iter 1/3 - loss 0.00537153 - samples/sec: 1.75 - lr: 0.020000\n",
      "2021-03-13 21:13:39,880 epoch 4 - iter 2/3 - loss 0.00913310 - samples/sec: 1.92 - lr: 0.020000\n",
      "2021-03-13 21:13:43,353 epoch 4 - iter 3/3 - loss 0.00664022 - samples/sec: 4.61 - lr: 0.020000\n",
      "2021-03-13 21:13:43,355 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:13:43,355 EPOCH 4 done: loss 0.0066 - lr 0.0200000\n",
      "2021-03-13 21:13:44,551 DEV : loss 0.2267598807811737 - score 1.0\n",
      "2021-03-13 21:13:44,552 BAD EPOCHS (no improvement): 3\n",
      "2021-03-13 21:13:44,554 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:13:55,249 epoch 5 - iter 1/3 - loss 0.00112469 - samples/sec: 1.51 - lr: 0.020000\n",
      "2021-03-13 21:14:04,407 epoch 5 - iter 2/3 - loss 0.00089071 - samples/sec: 1.75 - lr: 0.020000\n",
      "2021-03-13 21:14:07,021 epoch 5 - iter 3/3 - loss 0.11347519 - samples/sec: 6.12 - lr: 0.020000\n",
      "2021-03-13 21:14:07,023 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:14:07,024 EPOCH 5 done: loss 0.1135 - lr 0.0200000\n",
      "2021-03-13 21:14:08,295 DEV : loss 0.07668250799179077 - score 1.0\n",
      "2021-03-13 21:14:08,296 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:14:09,036 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:14:21,709 epoch 6 - iter 1/3 - loss 0.00109595 - samples/sec: 1.27 - lr: 0.020000\n",
      "2021-03-13 21:14:30,886 epoch 6 - iter 2/3 - loss 0.00161757 - samples/sec: 1.74 - lr: 0.020000\n",
      "2021-03-13 21:14:33,448 epoch 6 - iter 3/3 - loss 0.00127892 - samples/sec: 6.25 - lr: 0.020000\n",
      "2021-03-13 21:14:33,449 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:14:33,450 EPOCH 6 done: loss 0.0013 - lr 0.0200000\n",
      "2021-03-13 21:14:34,641 DEV : loss 0.10071611404418945 - score 1.0\n",
      "2021-03-13 21:14:34,642 BAD EPOCHS (no improvement): 1\n",
      "2021-03-13 21:14:34,643 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:14:46,430 epoch 7 - iter 1/3 - loss 0.00171248 - samples/sec: 1.36 - lr: 0.020000\n",
      "2021-03-13 21:14:55,091 epoch 7 - iter 2/3 - loss 0.00228969 - samples/sec: 1.85 - lr: 0.020000\n",
      "2021-03-13 21:14:57,461 epoch 7 - iter 3/3 - loss 0.00175866 - samples/sec: 6.75 - lr: 0.020000\n",
      "2021-03-13 21:14:57,462 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:14:57,463 EPOCH 7 done: loss 0.0018 - lr 0.0200000\n",
      "2021-03-13 21:14:58,734 DEV : loss 0.08047538250684738 - score 1.0\n",
      "2021-03-13 21:14:58,736 BAD EPOCHS (no improvement): 2\n",
      "2021-03-13 21:14:58,739 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:15:08,117 epoch 8 - iter 1/3 - loss 0.00022670 - samples/sec: 1.72 - lr: 0.020000\n",
      "2021-03-13 21:15:17,849 epoch 8 - iter 2/3 - loss 0.00027035 - samples/sec: 1.64 - lr: 0.020000\n",
      "2021-03-13 21:15:20,377 epoch 8 - iter 3/3 - loss 0.00040258 - samples/sec: 6.33 - lr: 0.020000\n",
      "2021-03-13 21:15:20,379 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:15:20,380 EPOCH 8 done: loss 0.0004 - lr 0.0200000\n",
      "2021-03-13 21:15:21,542 DEV : loss 0.07758019119501114 - score 1.0\n",
      "2021-03-13 21:15:21,544 BAD EPOCHS (no improvement): 3\n",
      "2021-03-13 21:15:21,546 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:15:32,455 epoch 9 - iter 1/3 - loss 0.00138259 - samples/sec: 1.48 - lr: 0.020000\n",
      "2021-03-13 21:15:44,470 epoch 9 - iter 2/3 - loss 0.00120939 - samples/sec: 1.33 - lr: 0.020000\n",
      "2021-03-13 21:15:46,391 epoch 9 - iter 3/3 - loss 0.00189923 - samples/sec: 8.33 - lr: 0.020000\n",
      "2021-03-13 21:15:46,393 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:15:46,394 EPOCH 9 done: loss 0.0019 - lr 0.0200000\n",
      "2021-03-13 21:15:47,714 DEV : loss 0.08373576402664185 - score 1.0\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-02.\n",
      "2021-03-13 21:15:47,716 BAD EPOCHS (no improvement): 4\n",
      "2021-03-13 21:15:47,718 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:15:56,980 epoch 10 - iter 1/3 - loss 0.00127331 - samples/sec: 1.74 - lr: 0.010000\n",
      "2021-03-13 21:16:07,614 epoch 10 - iter 2/3 - loss 0.00108411 - samples/sec: 1.50 - lr: 0.010000\n",
      "2021-03-13 21:16:10,315 epoch 10 - iter 3/3 - loss 0.00078639 - samples/sec: 5.93 - lr: 0.010000\n",
      "2021-03-13 21:16:10,319 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:16:10,321 EPOCH 10 done: loss 0.0008 - lr 0.0100000\n",
      "2021-03-13 21:16:11,468 DEV : loss 0.09019169211387634 - score 1.0\n",
      "2021-03-13 21:16:11,469 BAD EPOCHS (no improvement): 1\n",
      "2021-03-13 21:16:12,288 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:16:12,290 Testing using best model ...\n",
      "2021-03-13 21:16:12,292 loading file resources/taggers/go_emotions/best-model.pt\n",
      "init TARS\n",
      "2021-03-13 21:16:27,754 \t1.0\n",
      "2021-03-13 21:16:27,755 \n",
      "Results:\n",
      "- F-score (micro) 1.0\n",
      "- F-score (macro) 1.0\n",
      "- Accuracy 1.0\n",
      "\n",
      "By class:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             World News     1.0000    1.0000    1.0000        10\n",
      "            Sports News     1.0000    1.0000    1.0000        10\n",
      "Science-Technology News     1.0000    1.0000    1.0000        10\n",
      "          Business News     1.0000    1.0000    1.0000        10\n",
      "\n",
      "              micro avg     1.0000    1.0000    1.0000        40\n",
      "              macro avg     1.0000    1.0000    1.0000        40\n",
      "           weighted avg     1.0000    1.0000    1.0000        40\n",
      "            samples avg     1.0000    1.0000    1.0000        40\n",
      "\n",
      "2021-03-13 21:16:27,757 ----------------------------------------------------------------------------------------------------\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                              0.00      0.00      0.00         0\n",
      "          Business News       0.88      0.85      0.87        34\n",
      "Science-Technology News       0.80      0.76      0.78        21\n",
      "            Sports News       1.00      0.95      0.98        22\n",
      "             World News       0.84      0.91      0.87        23\n",
      "\n",
      "               accuracy                           0.87       100\n",
      "              macro avg       0.70      0.70      0.70       100\n",
      "           weighted avg       0.88      0.87      0.87       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/puneet/.virtualenvs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tars = get_model(k=10)\n",
    "sample_df_test_pred = sample_df_test.apply(predict, 1)\n",
    "print(classification_report(sample_df_test_pred.category,sample_df_test_pred.predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-tension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:31:35,662 loading file /Users/puneet/.flair/models/tars-base-v8.pt\n",
      "init TARS\n",
      "                                                  text  \\\n",
      "0    Bosnian Serb prime minister resigns  The prime...   \n",
      "1    EU to lift trade sanctions against US amid lin...   \n",
      "2      critical  flaws fixed in RealPlayer  RealNet...   \n",
      "3    CHELSEA DUO PAY CREDIT TO PSG  Chelsea striker...   \n",
      "4    Soyuz spacecraft docks with ISS  MOSCOW Oct  I...   \n",
      "..                                                 ...   \n",
      "115  Apple Launches ITunes Music Store in Canada Re...   \n",
      "116  Titan  Drumroll Please  Imagine an oil drum th...   \n",
      "117  Sun stands between Liberty and finals  NEW YOR...   \n",
      "118  Barrera earns majority decision over Morales i...   \n",
      "119  Bush Kerry Tentatively OK Three Debates  NEW Y...   \n",
      "\n",
      "                    category  \n",
      "0                 World News  \n",
      "1              Business News  \n",
      "2    Science-Technology News  \n",
      "3                Sports News  \n",
      "4    Science-Technology News  \n",
      "..                       ...  \n",
      "115  Science-Technology News  \n",
      "116  Science-Technology News  \n",
      "117              Sports News  \n",
      "118              Sports News  \n",
      "119               World News  \n",
      "\n",
      "[120 rows x 2 columns]\n",
      "size of training data is (120, 2)\n",
      "Corpus ready to load: Train 108 , Test: 120 \n",
      "2021-03-13 21:31:40,596 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [00:00<00:00, 39854.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:31:40,606 [b'World News', b'Business News', b'Science-Technology News', b'Sports News']\n",
      "2021-03-13 21:31:40,608 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:31:40,611 Model: \"TARSClassifier(\n",
      "  (document_embeddings): None\n",
      "  (decoder): None\n",
      "  (loss_function): None\n",
      "  (tars_model): TextClassifier(\n",
      "    (document_embeddings): TransformerDocumentEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (loss_function): CrossEntropyLoss()\n",
      "  )\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-03-13 21:31:40,612 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:31:40,613 Corpus: \"Corpus: 108 train + 12 dev + 120 test sentences\"\n",
      "2021-03-13 21:31:40,613 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:31:40,614 Parameters:\n",
      "2021-03-13 21:31:40,615  - learning_rate: \"0.02\"\n",
      "2021-03-13 21:31:40,616  - mini_batch_size: \"16\"\n",
      "2021-03-13 21:31:40,616  - patience: \"3\"\n",
      "2021-03-13 21:31:40,617  - anneal_factor: \"0.5\"\n",
      "2021-03-13 21:31:40,618  - max_epochs: \"10\"\n",
      "2021-03-13 21:31:40,619  - shuffle: \"True\"\n",
      "2021-03-13 21:31:40,620  - train_with_dev: \"False\"\n",
      "2021-03-13 21:31:40,620  - batch_growth_annealing: \"False\"\n",
      "2021-03-13 21:31:40,621 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:31:40,621 Model training base path: \"resources/taggers/go_emotions\"\n",
      "2021-03-13 21:31:40,622 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:31:40,623 Device: cpu\n",
      "2021-03-13 21:31:40,623 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:31:40,624 Embeddings storage mode: cpu\n",
      "2021-03-13 21:31:40,628 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 21:31:49,224 epoch 1 - iter 1/7 - loss 0.87146622 - samples/sec: 1.88 - lr: 0.020000\n",
      "2021-03-13 21:31:58,037 epoch 1 - iter 2/7 - loss 0.77223769 - samples/sec: 1.82 - lr: 0.020000\n",
      "2021-03-13 21:32:10,443 epoch 1 - iter 3/7 - loss 0.56228625 - samples/sec: 1.29 - lr: 0.020000\n",
      "2021-03-13 21:32:20,458 epoch 1 - iter 4/7 - loss 0.57051513 - samples/sec: 1.60 - lr: 0.020000\n",
      "2021-03-13 21:32:30,134 epoch 1 - iter 5/7 - loss 0.55605755 - samples/sec: 1.65 - lr: 0.020000\n",
      "2021-03-13 21:32:38,577 epoch 1 - iter 6/7 - loss 0.46554534 - samples/sec: 1.90 - lr: 0.020000\n",
      "2021-03-13 21:32:45,552 epoch 1 - iter 7/7 - loss 0.42598019 - samples/sec: 2.29 - lr: 0.020000\n",
      "2021-03-13 21:32:45,553 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:32:45,554 EPOCH 1 done: loss 0.4260 - lr 0.0200000\n",
      "2021-03-13 21:32:48,123 DEV : loss 0.013242833316326141 - score 1.0\n",
      "2021-03-13 21:32:48,125 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:32:49,094 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:32:59,427 epoch 2 - iter 1/7 - loss 0.00344674 - samples/sec: 1.56 - lr: 0.020000\n",
      "2021-03-13 21:33:11,085 epoch 2 - iter 2/7 - loss 0.00242327 - samples/sec: 1.37 - lr: 0.020000\n",
      "2021-03-13 21:33:21,977 epoch 2 - iter 3/7 - loss 0.00375129 - samples/sec: 1.47 - lr: 0.020000\n",
      "2021-03-13 21:33:31,560 epoch 2 - iter 4/7 - loss 0.02766495 - samples/sec: 1.67 - lr: 0.020000\n",
      "2021-03-13 21:33:43,713 epoch 2 - iter 5/7 - loss 0.02246330 - samples/sec: 1.32 - lr: 0.020000\n",
      "2021-03-13 21:33:53,240 epoch 2 - iter 6/7 - loss 0.05966478 - samples/sec: 1.68 - lr: 0.020000\n",
      "2021-03-13 21:34:00,958 epoch 2 - iter 7/7 - loss 0.05118942 - samples/sec: 2.07 - lr: 0.020000\n",
      "2021-03-13 21:34:00,960 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:34:00,961 EPOCH 2 done: loss 0.0512 - lr 0.0200000\n",
      "2021-03-13 21:34:03,418 DEV : loss 0.011066938750445843 - score 1.0\n",
      "2021-03-13 21:34:03,420 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:34:04,259 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:34:17,635 epoch 3 - iter 1/7 - loss 0.00789601 - samples/sec: 1.20 - lr: 0.020000\n",
      "2021-03-13 21:34:26,033 epoch 3 - iter 2/7 - loss 0.00780359 - samples/sec: 1.91 - lr: 0.020000\n",
      "2021-03-13 21:34:34,214 epoch 3 - iter 3/7 - loss 0.01006974 - samples/sec: 1.96 - lr: 0.020000\n",
      "2021-03-13 21:34:45,363 epoch 3 - iter 4/7 - loss 0.00781880 - samples/sec: 1.44 - lr: 0.020000\n",
      "2021-03-13 21:34:53,789 epoch 3 - iter 5/7 - loss 0.00629217 - samples/sec: 1.90 - lr: 0.020000\n",
      "2021-03-13 21:35:02,694 epoch 3 - iter 6/7 - loss 0.00576459 - samples/sec: 1.80 - lr: 0.020000\n",
      "2021-03-13 21:35:10,369 epoch 3 - iter 7/7 - loss 0.00506859 - samples/sec: 2.09 - lr: 0.020000\n",
      "2021-03-13 21:35:10,371 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:35:10,373 EPOCH 3 done: loss 0.0051 - lr 0.0200000\n",
      "2021-03-13 21:35:12,833 DEV : loss 0.0028236417565494776 - score 1.0\n",
      "2021-03-13 21:35:12,835 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:35:13,688 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:35:25,842 epoch 4 - iter 1/7 - loss 0.00021935 - samples/sec: 1.32 - lr: 0.020000\n",
      "2021-03-13 21:35:36,483 epoch 4 - iter 2/7 - loss 0.00024264 - samples/sec: 1.50 - lr: 0.020000\n",
      "2021-03-13 21:35:44,530 epoch 4 - iter 3/7 - loss 0.00063394 - samples/sec: 1.99 - lr: 0.020000\n",
      "2021-03-13 21:35:53,642 epoch 4 - iter 4/7 - loss 0.00061313 - samples/sec: 1.76 - lr: 0.020000\n",
      "2021-03-13 21:36:02,724 epoch 4 - iter 5/7 - loss 0.00077570 - samples/sec: 1.76 - lr: 0.020000\n",
      "2021-03-13 21:36:13,098 epoch 4 - iter 6/7 - loss 0.00068796 - samples/sec: 1.54 - lr: 0.020000\n",
      "2021-03-13 21:36:19,779 epoch 4 - iter 7/7 - loss 0.00072366 - samples/sec: 2.40 - lr: 0.020000\n",
      "2021-03-13 21:36:19,781 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:36:19,782 EPOCH 4 done: loss 0.0007 - lr 0.0200000\n",
      "2021-03-13 21:36:23,238 DEV : loss 0.005832410883158445 - score 1.0\n",
      "2021-03-13 21:36:23,240 BAD EPOCHS (no improvement): 1\n",
      "2021-03-13 21:36:23,242 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:36:34,429 epoch 5 - iter 1/7 - loss 0.00158107 - samples/sec: 1.44 - lr: 0.020000\n",
      "2021-03-13 21:36:45,072 epoch 5 - iter 2/7 - loss 0.00094749 - samples/sec: 1.50 - lr: 0.020000\n",
      "2021-03-13 21:36:54,960 epoch 5 - iter 3/7 - loss 0.00797932 - samples/sec: 1.62 - lr: 0.020000\n",
      "2021-03-13 21:37:03,634 epoch 5 - iter 4/7 - loss 0.00616014 - samples/sec: 1.84 - lr: 0.020000\n",
      "2021-03-13 21:37:12,781 epoch 5 - iter 5/7 - loss 0.00499588 - samples/sec: 1.75 - lr: 0.020000\n",
      "2021-03-13 21:37:23,583 epoch 5 - iter 6/7 - loss 0.00420318 - samples/sec: 1.48 - lr: 0.020000\n",
      "2021-03-13 21:37:31,491 epoch 5 - iter 7/7 - loss 0.00367225 - samples/sec: 2.02 - lr: 0.020000\n",
      "2021-03-13 21:37:31,493 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:37:31,494 EPOCH 5 done: loss 0.0037 - lr 0.0200000\n",
      "2021-03-13 21:37:34,012 DEV : loss 0.0027598233427852392 - score 1.0\n",
      "2021-03-13 21:37:34,013 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-13 21:37:34,848 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:37:44,513 epoch 6 - iter 1/7 - loss 0.01573881 - samples/sec: 1.67 - lr: 0.020000\n",
      "2021-03-13 21:37:53,777 epoch 6 - iter 2/7 - loss 0.00799201 - samples/sec: 1.73 - lr: 0.020000\n",
      "2021-03-13 21:38:01,888 epoch 6 - iter 3/7 - loss 0.00537205 - samples/sec: 1.97 - lr: 0.020000\n",
      "2021-03-13 21:38:10,302 epoch 6 - iter 4/7 - loss 0.00409150 - samples/sec: 1.90 - lr: 0.020000\n",
      "2021-03-13 21:38:18,990 epoch 6 - iter 5/7 - loss 0.00333419 - samples/sec: 1.84 - lr: 0.020000\n",
      "2021-03-13 21:38:28,900 epoch 6 - iter 6/7 - loss 0.00282534 - samples/sec: 1.61 - lr: 0.020000\n",
      "2021-03-13 21:38:37,246 epoch 6 - iter 7/7 - loss 0.00244938 - samples/sec: 1.92 - lr: 0.020000\n",
      "2021-03-13 21:38:37,248 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:38:37,249 EPOCH 6 done: loss 0.0024 - lr 0.0200000\n",
      "2021-03-13 21:38:39,650 DEV : loss 0.009675003588199615 - score 1.0\n",
      "2021-03-13 21:38:39,652 BAD EPOCHS (no improvement): 1\n",
      "2021-03-13 21:38:39,654 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-13 21:38:48,718 epoch 7 - iter 1/7 - loss 0.00050464 - samples/sec: 1.78 - lr: 0.020000\n",
      "2021-03-13 21:38:57,115 epoch 7 - iter 2/7 - loss 0.00041300 - samples/sec: 1.91 - lr: 0.020000\n",
      "2021-03-13 21:39:08,091 epoch 7 - iter 3/7 - loss 0.00031785 - samples/sec: 1.46 - lr: 0.020000\n",
      "2021-03-13 21:39:17,352 epoch 7 - iter 4/7 - loss 0.00032640 - samples/sec: 1.73 - lr: 0.020000\n",
      "2021-03-13 21:39:26,736 epoch 7 - iter 5/7 - loss 0.00030311 - samples/sec: 1.71 - lr: 0.020000\n"
     ]
    }
   ],
   "source": [
    "tars = get_model(k=30)\n",
    "sample_df_test_pred = sample_df_test.apply(predict, 1)\n",
    "print(classification_report(sample_df_test_pred.category,sample_df_test_pred.predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-world",
   "metadata": {},
   "source": [
    "# Fast ai reference\n",
    "\n",
    "https://github.com/Daammon/AG-News-Classifier/blob/master/Ag_news_Classif.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'k':[1,2,3, 10, 30 ]: 'accuracy':[77,79, 83, 87 ]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
